{"kernel_signature": "(('a_ptr', '*fp8e5', 'D', False), ('b_ptr', '*fp8e5', 'D', False), ('c_ptr', '*fp16', 'D', False), ('M', 'i32', 'D', False), ('N', 'i32', 'D', False), ('K', 'i32', 'D', False), ('BLOCK_SIZE_M', 'constexpr', 128, True), ('BLOCK_SIZE_N', 'constexpr', 64, True), ('BLOCK_SIZE_K', 'constexpr', 64, True))", "hash": "e83e5687ef13dcae980bb1730ac8f10134abd8a85d02f4d676098b23c706e5ad", "target": {"backend": "cuda", "arch": 90, "warp_size": 32}, "num_warps": 4, "num_ctas": 1, "num_stages": 3, "warp_size": 32, "maxnreg": null, "cluster_dims": [1, 1, 1], "ptx_version": null, "ptx_options": null, "ir_override": null, "enable_fp_fusion": true, "launch_cooperative_grid": false, "launch_pdl": false, "supported_fp8_dtypes": ["fp8e4b15", "fp8e4nv", "fp8e5"], "deprecated_fp8_dot_operand_dtypes": ["fp8e4b15"], "default_dot_input_precision": "tf32", "allowed_dot_input_precisions": ["tf32", "tf32x3", "ieee"], "max_num_imprecise_acc_default": 1073741824, "extern_libs": [["libdevice", "/home/ubuntu/anaconda3/envs/triton/lib/python3.12/site-packages/triton/backends/nvidia/lib/libdevice.10.bc"]], "debug": false, "backend_name": "cuda", "sanitize_overflow": true, "arch": "sm90", "instrumentation_mode": "", "triton_version": "3.5.1", "triton_runner_version": "0.3.2", "tensordesc_meta": [], "shared": 36912, "tmem_size": 0, "global_scratch_size": 384, "global_scratch_align": 128, "profile_scratch_size": 0, "profile_scratch_align": 1, "name": "matmul_kernel_make_tensor_desciptor"}